{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36567171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[0.471435159, -1.190975666, 1.432706952, -0.312651902, -0.720588744, 0.887162924, 0.859588385, -0.636523485, 0.015696373, -2.242684841, 1.150035739, 0.991946042, 0.953324139, -2.021254778, -0.334077358, 0.002118365, 0.405453414, 0.289091945, 1.321158171, -1.546905518, -0.20264633, -0.655969322, 0.193421379, 0.553438902, 1.318151593, -0.469305277, 0.675554097, -1.817027211, -0.183108538, 1.05896914, -0.397840232, 0.33743766, 1.047578573, 1.045938253, 0.863717318, -0.122091576, 0.124712951, -0.322794795, 0.841674685, 2.390960455, 0.076199591, -0.566445947, 0.036141936, -2.074977636, 0.247792199, -0.897156775, -0.136794835, 0.018289192, 0.755414009, 0.215268582, 0.841008782, -1.44581008, -1.401973248, -0.100918204, -0.54824245, -0.14461951, 0.354020327, -0.035513025, 0.56573832, 1.545658827, -0.97423631, -0.07034488, 0.307968855, -0.208498761], [0.291205347, 0.566533685, 0.503591776, 0.285295695, 0.484288126, 1.363481522, -0.78110528, -0.468017668, 1.224574327, -1.28110826, 0.875475526, -1.710715294, -0.450765103, 0.749163806, -0.203932866, -0.182175413, 0.680656016, -1.818498969, 0.047071636, 0.394844204, -0.248432055, -0.617706656, -0.682883978, 0.436257601, -1.703012824, 0.393710613, -0.479324013, -0.299016297, 0.694103301, 0.678629696, 0.239556, 0.151226625, 0.816127241, 1.893534422, 0.639632761, -0.962028861, -2.085265636, 1.930246711, -1.735348821, 1.210383654, 0.797435403, -0.37981078, 0.702562213, -0.850346267, 1.17681241, -0.5243361, 0.700907707, 0.98418808, -0.121728405, 2.365768671, 0.496142924, 0.796594858, -0.474020898, -0.056695718, 1.357797265, -0.80483371, -2.123620272, -0.333502442, -0.886719346, 0.334197938, 0.536783814, -0.743830383, -0.320203871, -0.91619885], [-0.319561392, -0.619993091, 0.156998381, -0.571455359, 1.057633162, -0.791488826, -0.524627328, 0.071878038, 1.910759449, 0.787964702, 0.513082147, -0.546416283, 1.043944597, 2.107785225, 1.45992744, 1.015405416, 0.749184608, -0.675521493, 0.440266401, 0.688971877, -0.276646137, 1.924533367, 0.41120401, 0.890764952, 0.226363227, -2.078617811, -0.387886226, -0.087106973, 1.126385808, 0.247111723, 0.121171802, 0.298983932, -0.157099143, -0.740469038, -1.247652888, 0.249455214, 0.581073344, 2.763844013, 0.39932543, 0.668488145, -0.275773734, 0.500482917, 0.863064885, -1.051627874, -1.392054081, 1.1539222, 1.181944132, 0.391371459, -0.88104707, 0.295079947, 1.863801122, -1.712273955, -1.407084584, 0.126781181, 0.003759848, -1.268994212, -0.838842928, 0.553921223, -0.504042745, -0.788440168, 1.529400706, 0.205454856, 0.313013136, 0.866520703], [0.527046442, 0.71111238, -0.21754548, 2.637791157, -1.742137671, -0.094434805, 1.431183696, 0.592758417, 0.170296893, -1.751706004, 0.288581312, -0.542579532, 0.171602383, 0.982817829, -0.025348902, -0.287552446, 0.924442887, -0.061246298, -0.731033325, -1.022773743, 0.995992959, 0.955557942, 0.713840783, 0.133370966, -0.807038307, -0.342010796, 1.908779621, 0.155923262, 0.759652555, -0.423006237, 0.181672752, 0.274492562, 0.067912355, -0.036982816, -0.170801029, 0.266973227, 1.382997274, -0.022460874, 0.13139537, 0.434437186, 0.264534056, 0.565658331, 0.58508426, -0.174298152, -1.071368694, -0.048460502, -0.845290363, 0.415100545, 0.425530583, -0.980724335, -0.427826107, 1.498569965, -0.360156566, -0.45824039, -1.337968349, -0.041386541, 0.821047962, 2.097800732, 1.282933235, 0.270337939, 1.00314033, 1.078673601, 0.340752691, -0.198074967], [-0.226632297, -0.923830748, 0.355838984, -1.270063519, -0.195472419, -0.463419408, 0.989414871, 1.388647437, 1.087713718, 0.438801259, -0.961602271, 1.245609879, 0.502925515, -0.631398797, -0.704252064, -0.240482539, 0.585599303, 0.352800548, -1.815557718, -0.910123825, -0.748527944, -0.108124927, 0.274778843, 0.237349764, -0.259843707, -0.312442183, 0.448509753, -0.059531964, -0.470014811, 0.349566758, -1.027468801, -0.306638479, 1.40617609, -1.249696732, -1.560148835, 1.557397604, -0.593356371, -0.170288518, 1.672626853, -0.540799797, -0.684128344, 0.599962115, -0.217199132, 0.331526518, -0.383364588, -0.781816065, 0.266237408, 0.279428035, -1.219625711, -0.723948896, -1.734778285, 0.271660775, 0.099112019, -0.363089919, -0.588226736, 0.025941713, -0.572302341, 1.105587006, -1.208015561, -1.339701056, 2.075185299, -1.489409685, -1.150953054, 0.419059813], [0.52354604, 0.821517289, -0.148741856, -0.045370411, -0.704492927, 1.730315566, 0.228927255, 1.092741013, -0.353571534, -0.030658865, -0.200171843, -0.481310248, 1.71142602, 1.435387135, -1.167520285, 0.040843423, 0.362018198, 0.572592199, 1.104460239, -0.425672024, 0.755688846, 0.010281458, 0.224585772, -1.134708285, -0.95152092, -0.127130449, 0.028944498, 2.104077339, 1.567514181, -0.62422961, -0.400644213, -1.137061596, -0.903159022, -1.097278118, -0.071309209, -1.319339037, -0.560092926, 0.164954558, -0.631585777, -0.867069781, -1.002562642, 1.207348228, 1.711987019, -0.624589503, -0.212145805, -1.193564177, 0.657585919, 0.200079888, 1.091259837, -0.489022046, 1.36822021, 0.891625106, 0.837566197, 0.514144719, -0.050049692, 0.74395287, -1.724050164, 0.089901574, 0.322739571, -0.377149433, -0.000220898, 1.050113678, -0.168699116, 0.797876477], [0.291495442, -0.224159017, 1.089270115, 1.011387587, 1.124645591, -1.870844126, 0.175738811, -0.776586354, -0.303864896, -1.24040246, -0.507572293, -0.354477227, -1.046010494, 0.393672764, -0.34564805, 1.313169599, 1.608318806, -0.219209239, -0.34848097, 0.301350445, -0.225297391, -0.66243434, 0.911714494, 1.19082427, -0.109699458, -0.3583377, 0.570309877, 0.391685665, 0.410169452, 0.707859457, -1.100796938, 1.56485033], [0.075131245, 0.995822847, -0.122947492, 1.000218987, -0.410987467, 0.17225574, 0.844083786, 1.17634654, 0.538464367, 0.471965373, 0.012564319, 0.092633344, -0.495587468, -0.968651414, 0.296983063, -0.0016801, 1.029705763, 2.089253426, -0.190857917, -1.584658742, 2.511214733, -1.239233613, -1.223668337, -0.335228652, 0.459929526, -0.640553534, 1.762568355, -0.085673019, 1.636178374, -0.544108272, -1.049998641, 0.254616678], [-2.21838069, -0.967505753, 0.60476476, 1.929671288, -0.82364136, 0.312028557, -0.785074294, 0.74008888, -0.436340094, -1.385222435, -0.054951929, -0.75883913, -0.663357437, -0.231392056, 0.313149989, 0.410588086, 0.96317786, 1.214784384, -1.301081777, 1.597000599, -0.7367239, 0.705918014, -1.031638861, 1.091346979, 0.495569527, 1.326480389, 0.841150045, 0.092408881, 1.089940786, 2.069623232, 0.958187997, -0.492901653], [0.205720469, 0.212830141, 1.968022823, 2.071340322, -1.155408263, -0.862113893, -0.821482003, -0.667993665, -0.368174613, 0.020118508, -0.823208272, -0.165480599, 0.720865846, 1.295918941, -0.527766705, -0.463393003, -0.150792241, -1.139341116, -0.954387128, 0.051836599, -0.147048116, -0.38397792, 1.209025264, 0.213923037, -0.113979712, 0.944944918, -0.1833933, 1.714323282, 0.024600169, 0.454132646, 0.272277683, 0.305823088], [-2.080322266, -0.038130075, -0.665514588, -0.205680072, 0.705880344, -2.612790823, -0.025293503, -0.178266197, -0.064637527, -1.204955697, -3.880898476, 0.974470377, 0.41516003, 1.751967311, 0.48501116, -0.170893714, 0.748870075, 0.629793286, 0.811053038, 2.133776188, 0.238459185, 1.798873305, -1.604648113, 0.118714854, 0.762238026, 1.836430788, -0.558974445, -0.183320954, -0.989050448, 0.775032043, -0.593328476, 1.20861876], [1.137676835, -0.117321059, 0.77494508, 0.181106701, -0.916110277, 0.39508307, -0.182491511, -0.790308297, 1.231065035, -0.275745958, 0.068552367, 0.911061943, 0.20670405, -0.696493626, -1.954489827, -0.363380224, -0.978326321, 0.877332091, -0.412389964, -2.13152194, 1.403688073, -1.479424715, -0.544142365, -0.391886532, -0.268758714, 1.034399509, -0.716313958, 0.373861462, -1.325217843, 1.276832581, 1.041066766, 0.119443722], [1.79676199, -0.684293687, -0.808941305, -0.62391597, 0.084044471, 1.3280164, -0.475252122, -0.110295936, 0.365986705, -0.702431619, -1.203935862, -1.076852679, -0.907946587, 0.956433594, -1.345016718, -0.86060822, -0.86722523, 0.323316008, -0.821200073, -2.121891737, 1.199785948, -0.415934294, 0.248672456, 0.407734305, 1.154716969, 0.674282074, -0.96363163, 0.698200226, 0.128444791, -0.262788564, 0.271131575, -0.240439191], [-0.171777323, 0.952694952, -0.076922573, 0.798864424, -0.894867539, 0.306629986, -1.1864537, -1.555331707, -0.161533937, 1.817726612, 0.023361051, 1.083019853, -0.045787584, 0.299750417, 0.666751623, 0.032851353, -2.334046841, 0.27720508, -1.712097287, 2.188139439, 0.671666145, 0.143354565, 0.345784038, 0.994534254, 0.701667488, 0.628217876, -0.050794944, -0.165088043, -0.188397869, -0.092102744, -1.244182944, 0.487327367], [0.767444253, 1.678209662, 0.658500314, 0.382662714, -1.098942757, -1.109419703, -1.394905686, 1.178619862, -0.528802335, 0.680076122, 1.252403617, 0.670394123, -1.539721012, 1.188747048, -0.319816679, -1.257209182, 0.405121267, 0.430917352, 1.242878199, -0.755557299, 0.393632919, -0.908652246, 1.499758244, -0.362490743, -0.621951282, -1.11422956, -1.86748004, 0.058838941, -0.63504827, -0.274831921, 0.436673045, -0.418646544], [0.287560821, -1.171541095, -1.160466313, 0.236877695, -0.755678773, -0.628463745, 0.608778954, -1.670083523, 1.456139207, 0.405231476, 1.732113242, -0.936009765, -0.383707225, 0.828951418, -0.766314864, 2.035702944, 0.044471923, -0.652855039, -0.679804504, -0.872873425, -0.649594128, -1.079842925, -0.106924266, 0.585986435, 2.217138529, 0.898644507, 2.550784111, 0.164857626, 0.194945693, -0.803888023, -0.364754438, 0.155144677], [0.027693814, -0.227798611, -1.920056343, -0.185534075, -0.148849189, 1.242005944, 1.029574513, 0.396024048, -0.886283159, 0.429236442, 0.691993415, 0.242694199, 1.524032831, 0.303921491, -0.112048946, -0.296838284, 0.148590043, 0.765040398, 0.779127896, 1.470279932, 0.17345807, 0.106671408, -0.818363845, 0.671649396, 0.087342113, 0.876469433, -0.266463518, 2.153441191, 1.249352336, 0.242006496, -0.832729518, 2.454218864], [-0.435008883, -0.57229358, -0.347763181, -0.646956623, -1.060128689, 0.401198059, -0.803533733, -0.324648857, 0.700600207, 0.765489936, -0.507772684, -0.024494857, 0.760747254, 1.381240606, 0.384539098, -1.074345469, 0.300155252, 0.513261557, -0.542382002, 0.078624077, -0.484999955, -0.086455666, 1.315709829, 0.208127886, -1.40185082, -0.824468791, 0.200417146, -0.128416777, 0.448427528, 1.211207986, 0.593436182, 0.647214532], [1.108549118, 0.322386235, -1.955976725, 0.371283591, -0.703777432, 0.55662185, 1.957003593, 0.841029704, 0.562552273, 0.442317069, -0.265071869, 1.22225225, 0.166502163, -1.243428946, 0.348579407, 0.632578969, 2.01338172, 0.781462908, 2.147151709, -0.908350527, -1.187041163, 1.617081523, -0.042681299, 0.367983699, 1.809185028, 1.020068407, 1.589721084, 1.238116741, -0.976524413, -0.887750387, -0.577326357, 0.80295527], [0.105937302, 0.580887139, -0.027568689, -2.467702866, -1.126164794, -0.269188315, -0.582966805, 0.312615812, 0.394690484, 0.315726161, -0.919243217, -2.247155666, -0.293478876, 2.053683281, 0.529404998, 0.428659499, -0.507449567, 0.530578554, 0.326187789, -0.594896257, 0.426921993, -0.064798981, -0.307341427, 1.012472749, 0.338268846, 0.746088743, 0.179772809, -0.9173733, 0.256107539, 0.084789008, -0.384506136, -1.297242284], [1.164225936, -0.446764648, 0.598128438, 0.192059055, -2.146925688, -0.885227263, -0.494391531, -1.024986506, -1.89283514, -0.311389357, -0.118667312, 0.833354533, -0.92884475, 1.581253171, -0.719876289, 0.671238065, 1.121292591, 1.171097159, 0.138431713, 1.045212388, -0.343289226, -0.841916621, -0.609347224, -0.159514397, -0.64645946, -0.227691293, -0.426238328, 0.377650023, 0.141158015, -0.035093676, -0.889643848, -0.746764839], [1.15539217, -1.48191762, 0.820604503, 0.073051281, 0.313430995, 1.818928719, -1.253966928, 1.558384657, 0.960891902, -0.935690999, -0.178707823, -0.26876694, 0.302024573, 0.615806282, -1.300890446, 0.018104235, 0.164287969, 1.333050013, 2.603918314, 0.397013426, -0.477669567, -0.103413738, 0.230021432, -0.867708921, -0.124483608, -0.761243105, 0.324422836, 0.340493411, -1.139498591, -0.362352878, -0.612578094, -0.060487684], [1.335226417, 0.850657642, 1.295027614, 0.050297897, 0.34954682, 0.087274574, 0.818709791, -0.474876165, -0.568756223, 0.058626417, -0.4891074, -0.356872737, -0.437070966, -0.243534356, -0.093778081, -0.615982831, 0.414649427, 0.202095732, -0.297560543, 0.681660593, 0.538310826, -0.614050984, 0.769057572, 2.06324172, 1.524718761, 0.389533967, -1.441940904, 0.845672131, -0.445312768, -1.492266059, 0.21178478, -0.367183387], [0.872331858, -1.755180478, 0.795485079, -2.007531166, 1.186133742, 0.62856102, -0.057842311, 1.855901718, 0.028483586, -0.181433737, 0.612399101, -0.763324261, -0.354961514, -0.261775821, 0.812125802, 0.482615352, -0.886511922, -0.037756979, -0.562953234, 0.897705734, 0.383232057, -1.324806333, 1.139269233, -0.055480622, 0.533784926, 0.490733415, 0.972823322, 0.806909204, 0.317545831, 0.051478405, -0.972116888, 0.159836113], [-1.302960753, 0.244866729, 0.679017186, 1.660737753, -2.031270266, -0.435329735, -0.879835784, 0.128831878, 0.055340979, 1.472032905, 0.525387704, -1.110955715, -0.18956627, 0.825639546, 2.4702425, 0.311087221, -0.583718777, 0.580508947, 0.832612753, -0.538230538, 0.261325568, 0.457331926, -0.209657833, -1.733198762, 0.576554239, 0.073786013, -1.602557421, 0.547601998, -1.968321562, -0.219554543, -0.249335334, 0.998315156], [-0.251973689, 0.566106379, -1.05376792, -0.358932167, 0.653291821, -0.069367215, 1.119934201, 1.841646791, 0.304780841, -0.819031537, 0.875894189, -0.172806337, 1.24984026, -0.922306895, -0.130690336, 1.304546475, 0.604692221, -0.232043609, 0.181585059, 0.463922918, -0.204516798, 1.462823629, 0.506149352, -1.986884594, 0.561083317, 0.343115777, -0.033852525, -0.061556499, -0.711204231, 3.220568419, -0.120111629, 0.34295845], [-0.487496316, -2.302743435, 0.934849203, 1.367166162, -1.180575252, -0.290912807, -1.939286947, 0.628705502, -0.222552329, 0.223107532, 0.051648572, 0.499167264, -0.811248004, -0.399346054, 0.514977872, -0.086921073, 0.560156643, -0.153577, 0.227588624, 1.302304506, -0.143113077, 0.614649713, -0.042085573, 0.789137423, -1.817363024, -0.581057727, 0.369804591, -0.433913201, 1.207046747, 1.456715465, -1.542686462, 0.778064847], [2.162058353, 0.517910361, 1.789766908, 0.375039548, -0.075969338, -0.678003132, 0.600541413, 0.493477315, 0.393853992, -0.906409085, 0.319150746, -0.499143869, -0.660399258, 0.077469699, 0.387551814, 0.97635287, -0.841298938, -0.145935565, 0.854822934, -0.285540909, 0.05384247, -0.603582263, -1.160375237, -0.812097609, -1.195849419, 0.562516451, -0.236867383, -0.219673693, -1.623322129, -0.634396076, 0.340876639, 2.833682775], [2.607840538, -0.106573604, 2.017828941, -0.840257525, -0.086164065, -0.786269307, 0.588488281, -0.346598446, -0.534316421, -1.089013577, 0.291769475, 0.253801793, -0.580686569, -0.213051334, -1.68681109, -0.857073009, -0.801161826, 1.386226892, -0.516565919, -0.190407649, 1.446356297, -2.098420382, -1.169858813, -0.418794304, -2.944573164, -0.098554336, -0.280782193, 0.7398507, 1.62718153, 0.030132484, -0.145601332, 0.227530435], [0.079685859, 1.020345211, -0.790109634, -1.155447364, -0.367505461, 1.263913631, 0.827048898, -0.572468996, 1.21167767, 1.792988181, 1.379124641, 2.049917221, 0.992011368, -0.930034816, -0.24939388, -1.002894521, -2.572706461, -0.046080381, 1.359182, 0.020971375, -0.210473105, 1.597260594, 0.92619139, -0.136542931, 1.168162584, -1.006245017, -0.61675936, 0.218939558, 0.717838287, 0.013333053, 1.348059893, 0.66217649], [-1.061083078, 0.817840397, 1.550795317, 1.225768328, 1.522541285, 0.137487188, 0.448477924, 0.952169895, -1.115069151, 0.651412129, -0.192102045, 0.337622613, 0.047543701, 1.471578717, 0.476930678, 2.010209084, 0.135824353, -0.828131497, -0.975346208, 1.2497015, 0.977551103, -0.555820346, -0.167353898, 1.810647726, 0.746234596, 1.477639914, -1.436650157, 0.954872072, 2.116853952, 0.368600488, 0.431669772, 0.882142961], [0.638453603, 1.807622194, 1.008900166, 0.672822237, 0.770658433, 1.533001661, 0.576320767, -0.819780886, -1.302051544, 1.599477172, 0.676874876, 1.324061632, 0.310813189, 0.504487276, 1.260331869, -1.258468032, 1.181067824, 1.232953429, -0.00692844, 0.367449075, 0.652186155, 0.24713102, 1.54326427, 1.326788902, 0.611316144, -0.682902455, -0.920411468, 0.938984513, 0.281447858, 1.162163019, -0.035100766, -0.825614989], [-0.986204624, -1.719757795, -2.230078459, -0.43910569, -2.397242069, 0.124508478, 1.493994832, -0.237058118, -1.482014537, 0.429888844, -0.782186329, 0.389665633, -0.480306208, -1.051903129, -0.987736046, -0.182059571, -0.379466832, 0.273247898, -0.138556376, 0.881904244, -0.51489681, -0.117796369, -0.108906433, -1.142649055, -1.349120259, 0.316879928, -0.128845483, -1.352643847, 0.161457583, 0.739064336, 0.165376946, -1.495079517], [0.241987541, -0.140923738, -0.653254569, 1.735855579, 0.493222594, 0.699760735, -0.490214825, 0.296281189, 0.574773788, -0.505159676, 0.702548265, -0.554584801, 0.7283355, -1.243858099, -1.107821822, -0.426698148, -2.755650997, -1.148347139, -1.234676957, -0.589449644, -1.313248396, -0.494713604, 0.669989467, -0.138093621, 0.058205836, -0.780497611, 0.33754161, -0.166919738, 0.105765693, 0.044486415, -0.368945926, -0.073951416], [-2.168434381, -0.562369585, 0.673750818, 1.223846555, -1.052629828, 0.985048771, -0.917995393, -1.016455054, 0.352714211, -1.608920097, 2.011646986, -0.963712573, -0.174083024, -0.299346149, 0.449206084, -0.385968715, 0.35722366, 0.609983146, 0.824893057, 0.101578079, 0.41808781, -0.774300039, -1.869866014, 0.812736928, 0.647766829, 0.498688549, 1.13713336, -0.016839838, 0.588231206, 0.124583609, -0.094401337, 0.953379869], [-1.063226819, 1.78832376, 1.376492023, 1.78669107, 0.079556257, 1.193013906, 0.078492977, 1.370478868, -0.700814426, -0.87238431, 0.487689048, 0.584534407, -1.753872991, 0.645651162, 1.551775813, -1.224763274, -1.221269369, 0.603332877, 0.159796968, 0.9737764, -0.957086504, -1.394082546, -0.970552504, -0.9483729, -0.496041536, 0.415224135, -0.031763643, -0.589993, 0.680320084, -0.371570438, -1.346570373, -0.996609807], [1.364528179, -1.88401556, -0.273768425, -0.235132962, 0.171791658, -0.906591773, 0.873799264, -0.464476585, -0.099607818, -0.909634829, 1.709746003, 0.853468537, -1.49854517, 1.579166651, 1.362725496, 1.286255717, -0.055209901, 0.153398424, -0.942942917, 0.103139788, 0.899135232, 0.163851008, 0.022556208, 0.985981166, 1.241803527, 0.246564701, -0.030313293, -0.801988602, -0.606592655, 1.151996136, 0.746980309, -1.20393765], [1.062560678, 0.043191936, -0.21490176, 0.105938189, 0.387693077, -0.000318425, 0.343792886, -0.96554184, 0.034085568, -0.371758163, -0.82922864, 0.929497421, 0.196961269, -0.275504321, 0.062247824, 0.249923304, -1.524407864, -0.090377219, 1.846290231, 1.041641355, 0.262791991, -0.360082686, 1.398947716, -0.062208861, -0.758216858, -0.085746512, 0.209345877, -0.149472624, 1.206538558, 0.12060415, 0.937266111, -1.332152724], [-2.152707338, 0.261239946, 0.819937885, -0.312776417, 0.281080812, -0.428825498, -0.191517115, -0.698572695, 0.286192387, 0.576377213, 0.210853219, -2.026795626, -1.371199846, 0.939968467, 0.490436763, 0.569744229, -0.361403763, 1.808590174, 0.328376025, -0.492476851, -0.690402448, 0.297137499, 1.037718654, 0.026601771, 0.448236197, 1.024917841, -0.469555348, -0.32337153, -0.086642727, -0.862428069, 1.15598619, -0.583644032], [1.802759528, -1.539525986, 1.144382, 0.137597933, -0.710266113, -0.479262918, -1.000971317, 0.447978675, -0.038644321, -0.466411978, 0.668338835, 2.243160009, -0.197019801, -0.667736351, -0.59068346, 1.688439965, 0.915396273, 0.750553131, -0.914734066, -0.60393703, -0.978893161, 0.559663951, 0.055128615, 1.063743114, -1.910979152, 1.101828575, -0.27337122, -0.231060728, -0.778534889, -0.878016531, -1.002812147, 0.486585379], [0.138377085, 1.537852883, -0.187720194, 1.19509387, 0.074916057, 2.357265472, -0.076403663, 0.322665691, -0.233626142, -0.634114265, -0.335548908, -0.363182902, -1.261114597, -1.562512159, -0.218659714, -1.123134375, -0.228739321, -1.036545038, -2.191538811, -0.673161268, -0.150803626, -1.201196194, 0.083551012, 1.819216847, -0.55625844, -1.013751149, 0.804957986, 1.138848782, -0.913211763, 2.047493219, -0.89478296, 1.059102774], [0.873966157, -1.16225493, 0.12618579, 0.505784869, 0.669515252, 0.483397782, -0.438356578, -0.139521465, 1.667876601, 0.906356215, 0.860304117, -0.00941371, -0.807548523, -0.784812868, -1.315515518, 0.687524498, -0.157235265, 0.303399771, -0.363406897, -0.552651167, 0.414420962, 0.175171033, -0.529515803, -0.067456946, 1.058814764, -0.117897928, -1.853420734, -0.701849461, 0.262396336, -1.724596024, 0.276580364, 1.073024154], [-0.267123073, 1.754908919, 0.059081186, 0.946492314, 0.212601811, -0.527676165, -1.095412135, 0.390338391, -0.147141859, -0.522368133, 0.63058269, 2.024914503, 1.573076367, 2.114488602, 0.620037675, 0.533758819, 1.723189473, -1.390599251, 0.613720238, 0.746699631, -1.504179358, -1.687467098, 1.206977844, -0.840076506, 2.232582569, -1.758686304, 1.168785334, -1.089552999, 1.977851629, 0.330122888, 1.481403708, -0.401635885], [-0.486692995, 0.337698817, 0.949077666, -0.491730571, -0.551621616, 0.046200193, 0.004158509, -0.858701706, 0.744886696, -0.392201394, -0.731709659, -0.045765847, -1.077162504, -0.882982969, 0.632930458, 0.703033686, -1.093268394, 0.186470017, 2.679853678, 1.07563138, -0.15880844, -0.058051921, -0.92826134, 0.912328303, 0.538362443, -1.819679618, 1.201520681, 0.946805716, -0.868582785, 1.471187115, -0.131622717, 0.867182016], [-0.176028103, 1.234488368, 0.594600856, -1.502078414, 0.187126964, -0.464783758, -1.040590763, -1.43639493, 1.247476935, 0.070861585, 0.073343933, 0.256215632, 0.06392438, -2.220642567, -0.654899776, 1.282637358, 0.779865324, 1.143395662, -0.332576543, -1.507492661, 0.920635402, -0.498645693, -1.391789436, 0.661659241, 1.179698706, 0.291845262, -0.825160205, -0.88117981, 0.296456665, -0.379912317, 0.767746806, -0.095246218], [-0.212638199, 1.383166552, 0.481297612, 0.097620323, -1.020895123, 0.000780357, 0.180238396, -1.130840778, -0.916283667, 0.214761257, 1.419389844, -0.534459531, 0.798228383, -0.663361013, 0.230646074, 1.692948222, 0.386671245, 1.322775483, -0.650471151, -0.037330527, 0.195718959, -1.773186922, -1.713767052, 1.229453206, 1.327581763, 1.630620837, -0.230174109, -0.440809429, -2.205679178, -1.375004649, -0.359555602, -1.19381249], [0.658424795, -0.277769804, -0.186851576, 1.239148378, 0.664974511, -1.033754468, 0.459361047, 0.391002953, 0.319686711, -0.060047183, 1.452571273, 1.736671805, -2.0364182, -1.741175413, -1.695446134, 0.662236392, -0.57079953, 0.887765348, -0.973146558, -1.801421165, 1.403986454, -1.198445082, -0.239509642, 1.655232787, 0.104430601, 1.293789864, -1.114275217, 0.512665272, 0.13073647, 0.31602028, 0.229450583, -0.431435913], [0.05316814, 0.644197524, -1.01241076, 2.37118125, 1.440502286, -1.092587233, -0.996140838, 0.867826343, -0.250733435, 0.768990338, -0.638298213, -0.192955926, 0.338915288, -2.666952372, -0.382754385, 0.852265239, -0.226793408, -1.738920093, 0.056061525, -1.817298651, -0.152310133, 0.724071681, 1.175361037, 0.081119612, 0.546146154, 0.302888095, 0.281125188, 0.555194378, 1.287912965, 1.410484552, -1.097561836, 0.706862867], [0.786451161, 0.643371522, 0.643775225, 0.097846493, 1.264975667, -1.929697514, -2.380088806, -0.514774859, 1.047516108, -0.068576165, -0.084317915, 0.837395132, 1.031121612, -0.335755169, -0.453867853, 0.889664948, -0.899207056, -0.147750199, 0.820535243, -0.285018474, -0.540141702, 1.155548215, -0.556504846, -0.439028829, 0.427961469, 2.006901741, -0.192463875, 0.013282048, -1.321203828, 0.622027934, 0.126299292, 0.485961109], [-1.37160027, -2.210345984, -0.197091758, 2.20474577, -1.528027177, -0.33313182, -1.227923036, -2.070221901, 1.539195061, -0.549061835, 0.490077704, 0.847190201, 1.222351313, 2.714404345, 0.419233561, 1.620244265, -2.179289579, 0.713244259, -1.646045089, -0.503103852, -0.290841281, 0.016647073, 0.526893914, -1.772352219, -0.239715099, -0.266734004, 1.118011475, 0.174665898, 1.775787354, -0.840945125, -0.760109007, -0.408395261], [-0.594286919, -0.449440926, 0.72895807, -0.747542143, -1.05836153, -1.336293221, 0.024043217, 1.37601757, -1.303818226, 1.080970883, -1.76090312, 0.566775739, 1.328074694, 0.366992176, -0.988723338, -1.26194346, -0.321691692, -0.368240148, -0.464782625, 0.567713082, -0.769218266, 0.658396125, 1.084815264, 1.00000453, -0.116615646, -2.040384769, 0.384750903, 0.461086959, -0.293192327, -0.820824623, 0.571812272, -0.477197021], [-0.934062779, 0.128169537, 1.695408821, 0.493748277, -0.642709613, -1.877012372, -0.252209783, -1.010279536, 0.169060022, 0.871627748, 0.805155575, 1.153723121, -0.520786166, -0.382088095, -0.43218109, -1.543349266, -1.374424577, 0.447084814, 0.96054095, -1.724841952, -1.776178002, 0.744448841, 1.468345761, -0.097931184, 0.485712349, 0.038514566, 0.670091629, -0.276242465, 0.145823821, -0.295499146, -0.583519936, 1.642153025], [-2.2578547, 0.878028035, 0.873955905, -0.710204005, 0.193910107, 0.801631987, 1.112428427, 0.063844159, -0.119534008, -1.228331685, -0.039036341, 1.205535769, -0.146349102, -0.548844397, 1.756115913, 1.134867549, 0.894274473, 0.20789437, -0.448674768, -0.069399662, -0.863012373, -0.421852738, -1.508397698, -1.625656962, 0.691437662, 0.038103346, -0.922522247, 1.363588214, 1.155415773, -1.921622038, 1.112435102, 0.768056333], [-1.877617002, 0.200499773, 0.145743951, 1.12510705, -2.562550783, 0.105367549, -0.887059331, 0.918532431, 1.266766906, 0.116320409, -0.129549325, 2.231617212, 1.702666879, -0.553565025, -1.695153475, 1.101846457, 0.138454318, -0.493156195, -1.466402411, -0.46418336, -0.308167368, 0.900568664, 0.147039905, -0.782699585, -1.744457126, -0.902175844, -1.602909446, 0.724455297, -2.208445787, 0.086100675, -1.099839926, -0.880690873], [0.216842353, 1.075552464, -0.906125546, -1.374149799, 0.892264903, 0.558056176, 0.043468274, -1.894047618, -0.052754208, 0.235815272, 0.871919215, -0.09988723, 1.407221437, 0.601900518, -0.650681257, -0.612802804, -0.699604511, -0.018685713, 0.618525386, -0.386814326, 0.045470517, 0.812000394, -0.359005302, 0.677693069, -0.09564735, -0.064902246, -1.329406857, 0.026288336, -0.394247293, -0.600908995, 0.658579469, -0.36763072], [0.644468725, -0.12569198, -1.759965062, 1.233214617, -0.284388781, 1.015536904, -1.332065463, -0.250101835, 0.456595182, -1.975677729, 0.010846647, 0.762171388, -1.460829258, -0.179175928, 0.238319203, -0.535621047, -0.529921651, 0.137983978, -0.837733984, 0.698422909, 0.351894617, 0.97081387, -0.349133492, 0.305100232, -0.57992065, -0.722569764, -1.016000867, 0.245752245, -0.533308804, -0.654210329, -0.567993402, 0.118324168], [1.70034802, -0.947120965, 0.5827865, -0.464592338, 0.2732912, -0.279709339, 0.51432091, 0.594095349, -0.511800885, 0.083885834, 0.619296849, 0.270565271, -0.407662153, -0.065683454, -0.675376356, -1.175901055, 1.600735307, 1.40385139, -0.720937848, 1.0009799, 0.529633105, -0.16958636, 0.752328157, 1.919620156, 0.475153625, 1.017659664, 0.278018236, 0.501594782, -2.168087721, 0.035199188, 0.446682572, -0.942350984], [0.600676417, -1.114046931, -0.146019176, -1.387762427, 1.242096186, 1.027383089, -1.49726522, 2.031154633, 0.053967845, 0.912482917, 0.307818145, 0.819143176, 1.141073346, -0.087856524, 1.124053597, 0.887032866, 0.494564414, 1.441723466, -0.572953582, -0.259456903, 0.90400666, -0.755812287, 0.206412196, -0.180730149, -0.250922918, -0.120505422, -0.693377256, -1.10491538, 1.34528327, 0.016848987, 0.383336157, 0.185282648], [-0.205291942, -1.010333896, 0.735149622, -0.946076095, 1.464885235, -1.668877959, -1.418028116, -0.157013938, 2.261312485, 0.519215643, -0.5819875, 0.842920661, -0.286237627, 0.02798821, 0.423808694, -1.040647388, -0.535190344, 0.163577422, 0.549972653, 1.317280889, 1.148311853, -1.710434675, -0.098582976, 1.016161919, -0.228032351, -0.835105121, -0.504081547, 1.941197276, 0.005251309, 1.087868571, 0.63812691, -0.885753393], [0.046990309, 1.361099839, -0.125290915, -0.431240797, 0.940798461, 0.207982868, 0.318853199, 1.80031538, -0.09856005, -0.692449033, 1.367750883, 1.359588027, -0.939327419, 0.588921428, 0.120063908, -0.032707799, -1.011169076, -1.594288707, 0.804691374, 0.047174167, 2.004438877, 0.144463032, 0.443465948, -0.483599633, -0.062805004, -0.202041909, -0.592102528, 0.074688919, -1.102349162, 1.642302513, -1.30706799, 0.725520968], [-0.907710791, -0.696014047, 0.077243842, -0.20487377, 0.728678763, -0.372724742, 0.50300175, -0.156823188, -1.396877527, 0.177807435, 0.201380059, 1.131907582, -0.119217329, -0.850342929, -0.714966953, 1.330486536, 1.218422294, 0.402345687, -0.020456824, -1.437366128, -0.383522213, -1.847018242, -0.587446511, -0.043138187, -0.260061741, 1.07148838, -0.082184628, 0.138825625, 0.294905484, 1.402692676, -0.622216403, -0.522486985], [0.076479204, 1.599217415, -0.517757237, -1.400622487, 0.538588881, 0.656282365, -0.413680762, -0.969591558, 1.234576106, -0.138589755, 2.370306253, -0.022254361, 1.033201694, 1.147629023, -0.077370718, -0.213998869, 0.195017099, 0.457562506, 0.354806185, 1.951207638, 1.568007946, 1.232565284, 0.174269348, 1.048957109, -0.420022309, -0.538878798, -0.889978111, -0.131982058, 0.227000192, -0.549052, -2.312831879, 1.055418968], [0.293322146, 0.238867074, -1.154307961, -0.273387104, 1.624333739, 0.413192183, -1.014702678, 0.752588212, -0.417716295, -0.277199686, 0.109492294, 1.214810252, 1.486980319, -1.241336346, 1.268661737, -1.711006403, -0.659809887, -0.678544164, 0.656132698, 0.140629396, 0.826829612, -0.28465426, 0.148631498, -0.079916649, -0.814469695, -0.503128707, -0.179154843, 0.480796218, 0.282567263, -0.458931178, 0.07241974, 0.014821514], [-2.944191694, -0.845766187, 1.522069335, 1.49244833, 0.447748452, -1.539530635, -0.21030958, -1.371900201, -0.351777047, 0.459433287, -0.506353855, 0.640694439, -0.266792208, 1.18239677, -0.082955807, -1.03333962, -1.029054761, -0.502779841, -0.083437838, -1.184253097, 0.926592767, -1.956782341, -0.273227364, -1.069246531, -1.490749598, 0.400249422, 1.981986642, -0.328438491, -1.130065918, 0.476352632, -1.342230439, 0.260728717], [-0.66466403, -0.72774297, -1.371997833, 0.789839208, -0.082323432, -1.286055207, -1.688256383, 0.183342993, -1.87486887, 0.495245636, -0.152949467, -0.905416608, -1.650508285, 1.724718571, 0.312900454, 0.875023603, 0.371097773, -1.58644855, -0.686348796, 1.953445435, 0.787232637, 0.446613908, 1.733019233, -1.521655798, -1.432532907, -2.030848742, -0.162260354, 1.83718276, 0.491367429, -0.035653979, -0.299576372, 0.883597434], [-0.295492142, -0.737888038, -2.602245569, -0.915270686, -0.664249361, 0.502045214, 0.714295745, 0.09184622, -0.065799862, 1.091241121, -0.466466337, 1.475288868, -0.398481667, 1.431693912, -0.494336218, -1.377344489, -0.24375169, 0.865319252, 0.38512969, 1.643199325, -1.334148169, 1.383531451, -0.337298781, -0.593549728, -0.626279712, 0.68138659, -1.468101382, 0.551331758, 0.938783407, 0.011352945, -1.425839782, 1.006222606], [0.677825809, -0.745510221, 0.451785356, 1.401160836, -0.426224023, 0.929504335, 0.42671442, -0.835182428, 1.003752828, 0.196103483, -2.215103626, -1.132625103, -0.293768436, -0.497251868, 0.348099321, -1.287349939, -1.488122344, -0.726220071, 0.507746935, 0.189871356, 0.980527759, 0.555155575, 0.369371206, -0.637441337, -3.434819221, -0.070282802, -0.278044045, -0.458229721, 0.496662676, -0.980485976, 0.691933393, -0.738466442], [-0.827210248, -0.190767944, 1.763744354, 0.453571677, -0.332415015, 1.463827014, 0.950344622, 0.547537386, -0.329872996, -1.247730017, -1.320199132, 0.963693917, -1.121311545, -0.509089768, -0.389376462, 0.150673866, 1.16433692, -0.332943678, 0.115181305, -1.048127294, -0.605733335, 1.418753862, -0.44283548, -0.43320024, 0.83500129, -1.041277528, 1.401810884, -1.093797445, 1.375670671, -0.544599295, 0.689777493, 1.050247908], [0.606620491, 1.446566701, -0.691401601, 0.955148757, 0.672142029, -0.355115652, -0.240102246, 0.232472777, 0.525020421, -0.012249905, -0.484402925, 0.761125088, -0.307001352, -0.21584788, -0.75089407, 0.283352911, -0.120901361, 0.702996969, -0.318598747, 0.2326148, -0.811898112, -1.919443011, -0.787729383, 2.559702873, -0.004541391, 0.119073883, -1.023547888, 2.175465584, 0.339051545, 0.575126231, -1.681742191, 0.551767468], [-0.476915807, 0.353992313, -0.187717736, -0.029780474, 0.314238518, 0.24181278, -0.449898362, 0.541301072, 1.853073359, -0.84688288, -0.229212552, -0.294929683, 0.491149217, -1.166303277, -1.725056767, -0.089117676, 0.355832666, 1.01553154, 0.861902177, 0.763406575, -0.280991554, -1.299122572, -1.739982247, -0.78051281, 0.182103202, 0.860109627, -0.35201934, -1.312125087, 1.158306122, 1.483899832, 0.010892897, 0.239734665], [-1.326253533, 1.661850333, -0.436045349, -1.394509912, 0.389587879, 1.044570446, -0.818063676, -0.986331642, 0.598684132, 1.935580969, -0.839189529, -0.463764876, 1.754786968, -0.87737, 2.580265045, 0.930416167], [-0.665526509, -1.537693381, -0.39793694, 1.052100778, 1.151208162, 0.523946822, -0.023123959, 1.687099934, 1.082645416, 1.117779136, -1.614126921, -0.385212541, 0.645167947, 0.080986835, 0.330914855, 1.172178626], [0.923182368, 1.20766592, -1.34111166, -0.551424265, 1.361259699, -0.046318788, 1.019738197, -0.639461577, 1.551021457, -0.134035483, -0.001633515, 0.36462, -1.794185042, 1.207086444, 0.173407122, 0.341976702], [1.894975662, -1.315814376, 1.45507884, -0.7464782, 0.851038933, 1.415685892, -0.929095566, -0.02756419, 0.046756767, -1.452287197, 1.575492263, -0.197377145, -0.219901174, -0.416243762, -0.821167529, 1.190342307], [-1.035114527, 0.489130527, -0.253340006, -1.948100328, -0.116555534, 0.800596952, -0.796154022, -0.382952332, -0.397373199, -0.717626929, 0.156995013, -0.344718188, -0.171208009, 0.538116157, 0.226387843, 1.541729093], [0.430744022, 0.076357313, -0.606393397, 1.167908311, -0.909901798, -0.149791986, 0.248037905, -0.332244694, 1.209697247, -0.292482555, -0.731596291, 1.077450752, 1.892185926, -0.9822191, -0.603046238, -0.501270235], [-0.871239305, 0.616610587, 1.445777655, -0.158187047, 0.506968737, -0.461109132, -0.92072475, 0.626933694, -0.37209028, 1.251878977, -0.234105304, -1.157688737, 0.920383155, 1.141664028, -0.867829382, 0.360347807], [0.592994809, -0.449622184, -0.369850576, 0.016136205, 0.880757034, 1.520258427, 0.693306983, 0.609804809, -0.790897906, 0.085400321, 0.789228499, 0.593940377, -0.51191926, -0.940527618, 0.566758633, 1.578890443], [0.766296923, 0.886189699, 0.800231218, -1.893141627, 0.097370796, 0.704359531, -0.601546109, -0.950843453, 0.710210681, 0.727630377, 0.103931807, -0.854161143, -0.466024846, 0.511145711, 0.618830442, 2.133546114], [0.931279719, 0.576357305, 2.851650953, 1.006811142, -0.322100669, 1.689510465, 0.360369802, 1.025997519, -0.692741752, 0.160925344, -0.343137294, 0.596047521, 1.057276368, -1.25661099, -0.306512386, 0.091600671], [2.442856073, -2.596933365, -0.505636275, 0.622558713, 0.604573548, -0.400495738, 0.708871722, -0.403097451, -0.791244924, -1.764964461, 0.313459903, 0.865482092, 0.940884769, 1.155804396, -0.131812125, 0.733884871], [-1.70226717, -2.080919504, 1.116942883, -0.354817748, 0.906181216, 2.250793934, -0.063945495, 0.619419932, -0.922730803, -0.635489881, -0.033289246, 0.49424994, 0.755143762, 1.202302217, 0.517969728, -1.29518187], [0.755483687, 0.331153691, -0.26440075, -2.109183788, 0.447095126, 2.141782045, -0.056079138, 1.133097172, 0.334239125, -1.218379974, 0.834774792, 0.426923007, 0.804016292, -0.702299595, 0.415145159, -0.918570876], [-0.289391667, -0.089290313, -0.460103601, -1.623745918, -0.656473458, 1.757190347, -0.120805465, 2.138495684, -1.718204737, 0.073358797, 0.30986917, -0.785033226, -0.352962613, -0.680478752, 0.38127771, -1.560564041], [1.152054191, 1.239473343, -0.686928272, 0.086382419, -1.614495635, 0.753276289, -0.098913133, 0.194970891, 1.509460688, -1.057375431, 1.8564533, -0.789329529, 0.193637043, 0.474019289, 0.157145768, 0.116303772], [1.654341936, 0.565929234, 0.620648384, 0.395444363, 1.377554417, -0.726137877, -0.73461175, -0.832455993, -0.195682898, -1.728133917, -1.274913669, -0.098441422, 0.39190501, 1.170050859, -0.869645476, 1.340765595], [-0.230216697, -0.868393779, -1.000848174, -0.727710843, 0.019696465, 0.67200321, -0.315184653, 0.534410059, -1.459275484, 0.266793191, -1.268733501, 1.710248709, 3.001147032, 0.494283229, 0.944405675, 0.348610818], [0.420967996, 0.039197791, 0.930934668, -0.358399689, 0.224534482, -1.138805628, 0.837308407, 0.583740771, -0.856663346, 0.363900781, -0.703653216, -0.995518506, 0.68802166, 0.780399859, -0.446845323, -1.332673669], [-0.697684944, 0.12104331, 0.674556851, 0.360613883, -1.326298594, -0.476895928, 1.684006095, -1.069343925, -0.140221387, 0.669293344, 0.478300452, -0.522426605, 0.025738088, -1.16490078, 1.03052783, 0.967762947], [0.04547409, 1.277502298, 0.0872982, 0.298645586, 1.177487135, -0.019651849, -0.072114706, 0.246775076, -0.211874008, -1.916667104, 0.694328249, -0.64318043, -1.192755342, -1.32929945, 0.499250293, 0.501820207], [-0.357401252, -0.312579572, 0.997971535, -0.767677188, -0.484959751, -1.115112305, 0.291985929, -1.847084641, 0.552188694, 0.926817477, 1.375455856, 0.476119906, -0.072192088, -0.157032371, -0.762535334, 1.728881478], [0.678576291, -0.912567437, 0.669902563, -0.641437531, 0.358395308, 0.516187012, -2.681261063, 0.658584118, -0.493938446, -0.276633352, -0.588059187, -1.666672587, -0.508506775, -1.262572289, -0.208026648, -1.484516144], [0.944352925, 0.571590424, 1.996541739, 0.352758646, -0.567697048, 1.185202003, 1.964407921, 0.171171635, 1.102610946, 1.156214952, -0.15814957, -0.11397358, -0.21979633, -0.459053427, -1.289293647, -0.630543947], [-1.104014039, -0.700519681, 0.882024169, -0.726815224, -1.641499996, 0.275159121, 0.075077936, 1.36162138, -1.096260786, -1.101648808, -0.442212224, -1.350462556, 0.184892058, 0.842839956, -0.987597883, -0.592877209], [-0.067531519, -0.381603867, 1.074411988, 1.641599536, 0.144428805, 1.060575604, 1.288050294, 0.178771675, -0.012873434, -1.721704841, 0.093787141, -0.944141567, 0.82116729, 0.418979317, 0.061492428, -0.538559198], [0.586881936, 0.249428496, -1.707180977, -0.469548881, -0.210222006, 0.242873177, 0.268970698, 1.621099949, 1.22601831, -1.131659031, 1.33828485, 0.547419131, 0.89437443, 0.579359651, 1.40656817, -1.340543151], [-1.200620055, 1.350824594, 0.415285975, 1.280989289, -1.633102894, -0.382860035, -1.350324392, 1.634721875, 1.245244741, -0.180405006, -0.058207057, 0.672828853, -0.043064624, -0.5143857, 1.566013932, 0.56336987], [-0.794282317, -0.506150663, -1.334647894, 0.028457163, -0.759240448, -0.248188108, -1.286149144, 0.293686718, -0.26442951, 0.932389557, 1.874325633, 1.11537385, -0.556782305, 0.259385616, 0.72613591, -1.682133198], [-0.317643583, -1.431211829, 0.848367691, -0.583804488, 0.209232867, -0.931723475, -0.408012271, 0.309107125, -0.95891118, 0.026626494, -0.679086804, 0.691105723, -1.087244034, 0.014233251, 0.164594978, 0.363792956], [-1.983703494, 0.986391962, -0.790055752, -0.228810906, -0.847048223, 1.09491837, 1.545186758, -1.746211171, -0.941808581, 0.334492505, -1.296333313, -0.46958521, 0.289865732, 0.360255837, 0.406847775, 0.134299666], [0.541464388, -0.505711019, 0.063429423, -0.307001203, -1.782771945, -0.65222168, -1.034704566, -0.675745487, 0.851039588, -0.113863349, -0.904885173, 1.299930692, -1.240736485, 1.212166429, -3.264203787, 1.113971949], [0.697191536, 0.090313695, -0.263629109, -0.813743591, -1.54515779, -1.615662575, -0.619753242, -0.860184908, -1.691732764, 0.304478437, 0.785147965, -0.185676619, 0.229603425, -1.785557508, 1.893452287, -0.767401755], [0.878799021], [1.88034451], [0.119211718], [0.359447688], [-1.006045461], [0.955108762], [1.238969445], [-0.026232874], [1.311864734], [-0.31132412], [-0.509010434], [-2.455444098], [-0.504541159], [-1.117219567], [1.379112601], [-0.521686554]]\n",
      "b: [[-0.635154963, -0.681020141, -1.501585722, -0.368925124, -0.352999359, 0.127384394, 0.517531335, 0.747836828, -0.809377551, -0.6326859, -0.446654826, -0.686920226, 0.209310085, 0.480308235, 0.138517201, -0.790100157, -0.38585034, 0.557666183, 0.3433474, 0.067343868, -0.615805149, -0.910603225, 2.171043158, -0.050554629, 1.55235219, 0.79615581, -0.545169473, -1.870703101, -0.562365413, -1.783594847, 0.07063438, -0.474537104, 0.252305865, -1.110924959, -0.089804456, -0.836549342, -0.414407074, 0.853309214, 0.614226639, -0.238566756, -1.055287957, 0.43343547, 1.764119506, 1.197646141, -0.948868275, -0.468651682, -1.260191321, 1.580285192, -0.555692673, 0.649815321, 0.83796829, 1.830009103, 0.269306391, -1.848756433, -0.749805033, -0.267733008, 0.631269991, -0.087142929, -0.069249019, -0.167822808, 0.649498701, 0.620435476, 0.144408464, 1.160045505], [0.665451467, 1.426555634, 1.15807724, -0.496191144, -0.010350391, 0.617205501, 0.336297214, -0.358237982, -0.995015502, -1.439778209, 0.364764392, 0.279524028, -0.35806641, 0.014738762, 2.008520126, 0.614190757, 1.495167613, 0.054757815, -0.786741972, 0.458817244, 0.111179955, -1.452647805, 0.940337896, -0.674392462, 0.085799441, 0.568131268, -0.097896002, 1.102557659, -0.338329643, -0.908826768, 0.798650682, 0.019666694], [-1.027925849, -1.870784402, 0.661100447, -1.804633021, 1.165535808, 0.663857937, 0.156077534, 0.413613558, 1.211116314, -0.176121324, 0.942437828, 0.633435845, -0.113880299, 0.457996637, -0.615560591, 0.385285527], [1.508889437]]\n",
      "Iteration 0, Cost: 14.4802, Accuracy: 0.0000\n",
      "Iteration 100, Cost: 0.0000, Accuracy: 1.0000\n",
      "Iteration 200, Cost: 0.0000, Accuracy: 1.0000\n",
      "Iteration 300, Cost: 0.0000, Accuracy: 1.0000\n",
      "Iteration 400, Cost: 0.0000, Accuracy: 1.0000\n",
      "Iteration 500, Cost: 0.0000, Accuracy: 1.0000\n",
      "Iteration 600, Cost: 0.0000, Accuracy: 1.0000\n",
      "Iteration 700, Cost: 0.0000, Accuracy: 1.0000\n",
      "Iteration 800, Cost: 0.0000, Accuracy: 1.0000\n",
      "Iteration 900, Cost: 0.0000, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def csv_to_numeric_array(filename):\n",
    "    data = []\n",
    "    with open(filename, newline=\"\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            converted_row = []\n",
    "            for item in row:\n",
    "                try:\n",
    "                    # Try converting to float (covers both int & decimal)\n",
    "                    converted_row.append(float(item))\n",
    "                except ValueError:\n",
    "                    # Skip non-numeric elements\n",
    "                    continue\n",
    "            if converted_row:   # only add non-empty rows\n",
    "                data.append(converted_row)\n",
    "    return data\n",
    "\n",
    "# Load data from CSV files\n",
    "arr1 = csv_to_numeric_array(\"W.csv\")\n",
    "arr2 = csv_to_numeric_array(\"b.csv\")\n",
    "\n",
    "print(\"W:\", arr1)\n",
    "print(\"b:\", arr2)\n",
    "\n",
    "def initialize_parameters(arr1, arr2):\n",
    "    # Flatten the arrays\n",
    "    arr1_flat = [item for sublist in arr1 for item in sublist]\n",
    "    arr2_flat = [item for sublist in arr2 for item in sublist]\n",
    "    \n",
    "    # Reshape weights according to network architecture\n",
    "    W1 = np.array(arr1_flat[0:6*64]).reshape(64, 6)\n",
    "    W2 = np.array(arr1_flat[6*64:6*64+64*32]).reshape(32, 64)\n",
    "    W3 = np.array(arr1_flat[6*64+64*32:6*64+64*32+32*16]).reshape(16, 32)\n",
    "    W4 = np.array(arr1_flat[6*64+64*32+32*16:6*64+64*32+32*16+16*1]).reshape(1, 16)\n",
    "    \n",
    "    # Extract biases\n",
    "    B1 = np.array(arr2_flat[0:64]).reshape(64, 1)\n",
    "    B2 = np.array(arr2_flat[64:64+32]).reshape(32, 1)\n",
    "    B3 = np.array(arr2_flat[64+32:64+32+16]).reshape(16, 1)\n",
    "    B4 = np.array(arr2_flat[64+32+16:64+32+16+1]).reshape(1, 1)\n",
    "    \n",
    "    return W1, B1, W2, B2, W3, B3, W4, B4\n",
    "\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    # Clip Z to avoid overflow in exp\n",
    "    Z = np.clip(Z, -500, 500)\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def forward_propagation(X, W1, B1, W2, B2, W3, B3, W4, B4):\n",
    "    # Reshape X to be a column vector\n",
    "    X = X.reshape(-1, 1)\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + B1\n",
    "    A1 = ReLU(Z1)\n",
    "    \n",
    "    Z2 = np.dot(W2, A1) + B2\n",
    "    A2 = ReLU(Z2)\n",
    "    \n",
    "    Z3 = np.dot(W3, A2) + B3\n",
    "    A3 = ReLU(Z3)\n",
    "    \n",
    "    Z4 = np.dot(W4, A3) + B4\n",
    "    A4 = sigmoid(Z4)\n",
    "    \n",
    "    return Z1, A1, Z2, A2, Z3, A3, Z4, A4\n",
    "\n",
    "def compute_cost(A4, Y):\n",
    "    m = Y.shape[1]\n",
    "    # Clip A4 to avoid log(0)\n",
    "    A4 = np.clip(A4, 1e-10, 1 - 1e-10)\n",
    "    cost = -np.sum(Y * np.log(A4) + (1 - Y) * np.log(1 - A4)) / m\n",
    "    return cost\n",
    "\n",
    "def backward_propagation(X, Y, W1, B1, W2, B2, W3, B3, W4, B4, Z1, A1, Z2, A2, Z3, A3, Z4, A4):\n",
    "    m = 1  # Since we're processing one sample at a time\n",
    "    \n",
    "    # Reshape X and Y\n",
    "    X = X.reshape(-1, 1)\n",
    "    Y = Y.reshape(1, 1)\n",
    "    \n",
    "    # Output layer gradient\n",
    "    dZ4 = A4 - Y\n",
    "    dW4 = (1/m) * np.dot(dZ4, A3.T)\n",
    "    dB4 = (1/m) * np.sum(dZ4, axis=1, keepdims=True)\n",
    "    \n",
    "    # Third hidden layer gradient\n",
    "    dA3 = np.dot(W4.T, dZ4)\n",
    "    dZ3 = dA3 * (Z3 > 0)\n",
    "    dW3 = (1/m) * np.dot(dZ3, A2.T)\n",
    "    dB3 = (1/m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    \n",
    "    # Second hidden layer gradient\n",
    "    dA2 = np.dot(W3.T, dZ3)\n",
    "    dZ2 = dA2 * (Z2 > 0)\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "    dB2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    # First hidden layer gradient\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * (Z1 > 0)\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T)\n",
    "    dB1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    return dW1, dB1, dW2, dB2, dW3, dB3, dW4, dB4\n",
    "\n",
    "def update_parameters(W1, B1, W2, B2, W3, B3, W4, B4, dW1, dB1, dW2, dB2, dW3, dB3, dW4, dB4, learning_rate):\n",
    "    W1 -= learning_rate * dW1\n",
    "    B1 -= learning_rate * dB1\n",
    "    W2 -= learning_rate * dW2\n",
    "    B2 -= learning_rate * dB2\n",
    "    W3 -= learning_rate * dW3\n",
    "    B3 -= learning_rate * dB3\n",
    "    W4 -= learning_rate * dW4\n",
    "    B4 -= learning_rate * dB4\n",
    "    \n",
    "    return W1, B1, W2, B2, W3, B3, W4, B4\n",
    "\n",
    "def get_predictions(A4):\n",
    "    return (A4 > 0.5).astype(int)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.mean(predictions == Y)\n",
    "\n",
    "def gradient_descent(X, Y, alpha, iterations, arr1, arr2):\n",
    "    W1, B1, W2, B2, W3, B3, W4, B4 = initialize_parameters(arr1, arr2)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Forward propagation\n",
    "        Z1, A1, Z2, A2, Z3, A3, Z4, A4 = forward_propagation(X, W1, B1, W2, B2, W3, B3, W4, B4)\n",
    "        \n",
    "        # Compute cost\n",
    "        cost = compute_cost(A4, Y.reshape(1, -1))\n",
    "        \n",
    "        # Backward propagation\n",
    "        dW1, dB1, dW2, dB2, dW3, dB3, dW4, dB4 = backward_propagation(\n",
    "            X, Y, W1, B1, W2, B2, W3, B3, W4, B4, Z1, A1, Z2, A2, Z3, A3, Z4, A4\n",
    "        )\n",
    "        \n",
    "        # Update parameters\n",
    "        W1, B1, W2, B2, W3, B3, W4, B4 = update_parameters(\n",
    "            W1, B1, W2, B2, W3, B3, W4, B4, \n",
    "            dW1, dB1, dW2, dB2, dW3, dB3, dW4, dB4, alpha\n",
    "        )\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            predictions = get_predictions(A4)\n",
    "            accuracy = get_accuracy(predictions, Y.reshape(1, -1))\n",
    "            print(f\"Iteration {i}, Cost: {cost:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return W1, B1, W2, B2, W3, B3, W4, B4\n",
    "\n",
    "# Training data\n",
    "x_train = np.array([1/9, 2/9, 3/9, 4/9, 5/9, 6/9])\n",
    "y_train = np.array([0])\n",
    "\n",
    "# Train the network\n",
    "W1, B1, W2, B2, W3, B3, W4, B4 = gradient_descent(x_train, y_train, 0.1, 1000, arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55c2a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save weights and biases in the required CSV format\n",
    "def save_updated_parameters(W1, B1, W2, B2, W3, B3, W4, B4):\n",
    "    with open('dw_123456.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        # W1\n",
    "        matrix = W1.T  # Transpose back to (6,64)\n",
    "        for row in matrix:\n",
    "            writer.writerow(['{:.16f}'.format(val) for val in row])\n",
    "        # W2\n",
    "        matrix = W2.T  # (64,32)\n",
    "        for row in matrix:\n",
    "            writer.writerow(['{:.16f}'.format(val) for val in row])\n",
    "        # W3\n",
    "        matrix = W3.T  # (32,16)\n",
    "        for row in matrix:\n",
    "            writer.writerow(['{:.16f}'.format(val) for val in row])\n",
    "        # W4\n",
    "        matrix = W4.T  # (16,1)\n",
    "        for row in matrix:\n",
    "            writer.writerow(['{:.16f}'.format(val) for val in row])\n",
    "    \n",
    "    with open('db_123456.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['{:.16f}'.format(val) for val in B1.flatten()])\n",
    "        writer.writerow(['{:.16f}'.format(val) for val in B2.flatten()])\n",
    "        writer.writerow(['{:.16f}'.format(val) for val in B3.flatten()])\n",
    "        writer.writerow(['{:.16f}'.format(val) for val in B4.flatten()])\n",
    "\n",
    "# Call the save function\n",
    "save_updated_parameters(W1, B1, W2, B2, W3, B3, W4, B4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59cbc355",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'weights btw layer0 to layer1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 157\u001b[0m\n\u001b[0;32m    154\u001b[0m index_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m123456\u001b[39m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# Initialize neural network\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m nn \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mW.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n\u001b[0;32m    160\u001b[0m dw, db \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mcompute_gradients(index_number)\n",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m, in \u001b[0;36mNeuralNetwork.__init__\u001b[1;34m(self, weights_file, biases_file)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights_file, biases_file):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Load weights and biases from CSV files\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_biases(biases_file)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Define activation functions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m, in \u001b[0;36mNeuralNetwork.load_weights\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     20\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mnext\u001b[39m(reader)  \u001b[38;5;66;03m# Skip header\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Reshape weights according to network architecture\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Input to Hidden1: 6x64\u001b[39;00m\n\u001b[0;32m     26\u001b[0m w1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m6\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'weights btw layer0 to layer1'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, weights_file, biases_file):\n",
    "        # Load weights and biases from CSV files\n",
    "        self.weights = self.load_weights(weights_file)\n",
    "        self.biases = self.load_biases(biases_file)\n",
    "        \n",
    "        # Define activation functions\n",
    "        self.relu = lambda x: np.maximum(0, x)\n",
    "        self.sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        # Define derivatives of activation functions\n",
    "        self.relu_derivative = lambda x: (x > 0).astype(np.float32)\n",
    "        self.sigmoid_derivative = lambda x: x * (1 - x)\n",
    "    \n",
    "    def load_weights(self, filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)  # Skip header\n",
    "            data = [list(map(np.float32, row)) for row in reader]\n",
    "        \n",
    "        # Reshape weights according to network architecture\n",
    "        # Input to Hidden1: 6x64\n",
    "        w1 = np.array(data[0:6])\n",
    "        # Hidden1 to Hidden2: 64x32\n",
    "        w2 = np.array(data[6:6+64])\n",
    "        # Hidden2 to Hidden3: 32x16\n",
    "        w3 = np.array(data[6+64:6+64+32])\n",
    "        # Hidden3 to Output: 16x1\n",
    "        w4 = np.array(data[6+64+32:6+64+32+16])\n",
    "        \n",
    "        return [w1, w2, w3, w4]\n",
    "    \n",
    "    def load_biases(self, filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)  # Skip header\n",
    "            data = [list(map(np.float32, row)) for row in reader]\n",
    "        \n",
    "        # Reshape biases according to network architecture\n",
    "        # Hidden1: 64\n",
    "        b1 = np.array(data[0]).reshape(-1, 1)\n",
    "        # Hidden2: 32\n",
    "        b2 = np.array(data[1]).reshape(-1, 1)\n",
    "        # Hidden3: 16\n",
    "        b3 = np.array(data[2]).reshape(-1, 1)\n",
    "        # Output: 1\n",
    "        b4 = np.array(data[3]).reshape(-1, 1)\n",
    "        \n",
    "        return [b1, b2, b3, b4]\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        # Store intermediate values for backpropagation\n",
    "        self.activations = [x.reshape(-1, 1)]\n",
    "        self.z_values = []\n",
    "        \n",
    "        # Hidden Layer 1\n",
    "        z1 = self.weights[0].T @ self.activations[0] + self.biases[0]\n",
    "        a1 = self.relu(z1)\n",
    "        self.z_values.append(z1)\n",
    "        self.activations.append(a1)\n",
    "        \n",
    "        # Hidden Layer 2\n",
    "        z2 = self.weights[1].T @ a1 + self.biases[1]\n",
    "        a2 = self.relu(z2)\n",
    "        self.z_values.append(z2)\n",
    "        self.activations.append(a2)\n",
    "        \n",
    "        # Hidden Layer 3\n",
    "        z3 = self.weights[2].T @ a2 + self.biases[2]\n",
    "        a3 = self.relu(z3)\n",
    "        self.z_values.append(z3)\n",
    "        self.activations.append(a3)\n",
    "        \n",
    "        # Output Layer\n",
    "        z4 = self.weights[3].T @ a3 + self.biases[3]\n",
    "        a4 = self.sigmoid(z4)\n",
    "        self.z_values.append(z4)\n",
    "        self.activations.append(a4)\n",
    "        \n",
    "        return a4\n",
    "    \n",
    "    def backpropagation(self):\n",
    "        # Initialize gradients\n",
    "        dw = [np.zeros_like(w) for w in self.weights]\n",
    "        db = [np.zeros_like(b) for b in self.biases]\n",
    "        \n",
    "        # Output layer gradient\n",
    "        delta = 1  # output/output = 1\n",
    "        delta *= self.sigmoid_derivative(self.activations[4])  # output/z4\n",
    "        \n",
    "        db[3] = delta\n",
    "        dw[3] = self.activations[3] @ delta.T\n",
    "        \n",
    "        # Hidden Layer 3\n",
    "        delta = self.weights[3] @ delta  # output/a3\n",
    "        delta *= self.relu_derivative(self.z_values[2])  # output/z3\n",
    "        \n",
    "        db[2] = delta\n",
    "        dw[2] = self.activations[2] @ delta.T\n",
    "        \n",
    "        # Hidden Layer 2\n",
    "        delta = self.weights[2] @ delta  # output/a2\n",
    "        delta *= self.relu_derivative(self.z_values[1])  # output/z2\n",
    "        \n",
    "        db[1] = delta\n",
    "        dw[1] = self.activations[1] @ delta.T\n",
    "        \n",
    "        # Hidden Layer 1\n",
    "        delta = self.weights[1] @ delta  # output/a1\n",
    "        delta *= self.relu_derivative(self.z_values[0])  # output/z1\n",
    "        \n",
    "        db[0] = delta\n",
    "        dw[0] = self.activations[0] @ delta.T\n",
    "        \n",
    "        return dw, db\n",
    "    \n",
    "    def preprocess_input(self, index_number):\n",
    "        # Split into digits and normalize\n",
    "        digits = [int(d) for d in str(index_number)]\n",
    "        return np.array(digits, dtype=np.float32) / 9.0\n",
    "    \n",
    "    def compute_gradients(self, index_number):\n",
    "        # Preprocess input\n",
    "        x = self.preprocess_input(index_number)\n",
    "        \n",
    "        # Forward pass\n",
    "        self.forward_pass(x)\n",
    "        \n",
    "        # Backpropagation\n",
    "        dw, db = self.backpropagation()\n",
    "        \n",
    "        return dw, db\n",
    "\n",
    "def save_gradients(dw, db, dw_filename, db_filename):\n",
    "    # Save weight gradients\n",
    "    with open(dw_filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for layer in dw:\n",
    "            for row in layer:\n",
    "                writer.writerow([f\"{x:.16f}\" for x in row])\n",
    "    \n",
    "    # Save bias gradients\n",
    "    with open(db_filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for layer in db:\n",
    "            writer.writerow([f\"{x:.16f}\" for x in layer.flatten()])\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your index number\n",
    "    index_number = 123456\n",
    "    \n",
    "    # Initialize neural network\n",
    "    nn = NeuralNetwork('W.csv', 'b.csv')\n",
    "    \n",
    "    # Compute gradients\n",
    "    dw, db = nn.compute_gradients(index_number)\n",
    "    \n",
    "    # Save gradients to CSV files\n",
    "    save_gradients(dw, db, 'dw.csv', 'db.csv')\n",
    "    \n",
    "    print(\"Gradients computed and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee88cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights btw layer0 to layer1</th>\n",
       "      <th>0.471435159</th>\n",
       "      <th>-1.190975666</th>\n",
       "      <th>1.432706952</th>\n",
       "      <th>-0.312651902</th>\n",
       "      <th>-0.720588744</th>\n",
       "      <th>0.887162924</th>\n",
       "      <th>0.859588385</th>\n",
       "      <th>-0.636523485</th>\n",
       "      <th>0.015696373</th>\n",
       "      <th>...</th>\n",
       "      <th>-0.54824245</th>\n",
       "      <th>-0.14461951</th>\n",
       "      <th>0.354020327</th>\n",
       "      <th>-0.035513025</th>\n",
       "      <th>0.56573832</th>\n",
       "      <th>1.545658827</th>\n",
       "      <th>-0.97423631</th>\n",
       "      <th>-0.07034488</th>\n",
       "      <th>0.307968855</th>\n",
       "      <th>-0.208498761</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weights btw layer0 to layer1</td>\n",
       "      <td>0.291205</td>\n",
       "      <td>0.566534</td>\n",
       "      <td>0.503592</td>\n",
       "      <td>0.285296</td>\n",
       "      <td>0.484288</td>\n",
       "      <td>1.363482</td>\n",
       "      <td>-0.781105</td>\n",
       "      <td>-0.468018</td>\n",
       "      <td>1.224574</td>\n",
       "      <td>...</td>\n",
       "      <td>1.357797</td>\n",
       "      <td>-0.804834</td>\n",
       "      <td>-2.123620</td>\n",
       "      <td>-0.333502</td>\n",
       "      <td>-0.886719</td>\n",
       "      <td>0.334198</td>\n",
       "      <td>0.536784</td>\n",
       "      <td>-0.743830</td>\n",
       "      <td>-0.320204</td>\n",
       "      <td>-0.916199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weights btw layer0 to layer1</td>\n",
       "      <td>-0.319561</td>\n",
       "      <td>-0.619993</td>\n",
       "      <td>0.156998</td>\n",
       "      <td>-0.571455</td>\n",
       "      <td>1.057633</td>\n",
       "      <td>-0.791489</td>\n",
       "      <td>-0.524627</td>\n",
       "      <td>0.071878</td>\n",
       "      <td>1.910759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>-1.268994</td>\n",
       "      <td>-0.838843</td>\n",
       "      <td>0.553921</td>\n",
       "      <td>-0.504043</td>\n",
       "      <td>-0.788440</td>\n",
       "      <td>1.529401</td>\n",
       "      <td>0.205455</td>\n",
       "      <td>0.313013</td>\n",
       "      <td>0.866521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weights btw layer0 to layer1</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>0.711112</td>\n",
       "      <td>-0.217545</td>\n",
       "      <td>2.637791</td>\n",
       "      <td>-1.742138</td>\n",
       "      <td>-0.094435</td>\n",
       "      <td>1.431184</td>\n",
       "      <td>0.592758</td>\n",
       "      <td>0.170297</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.337968</td>\n",
       "      <td>-0.041387</td>\n",
       "      <td>0.821048</td>\n",
       "      <td>2.097801</td>\n",
       "      <td>1.282933</td>\n",
       "      <td>0.270338</td>\n",
       "      <td>1.003140</td>\n",
       "      <td>1.078674</td>\n",
       "      <td>0.340753</td>\n",
       "      <td>-0.198075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weights btw layer0 to layer1</td>\n",
       "      <td>-0.226632</td>\n",
       "      <td>-0.923831</td>\n",
       "      <td>0.355839</td>\n",
       "      <td>-1.270064</td>\n",
       "      <td>-0.195472</td>\n",
       "      <td>-0.463419</td>\n",
       "      <td>0.989415</td>\n",
       "      <td>1.388647</td>\n",
       "      <td>1.087714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588227</td>\n",
       "      <td>0.025942</td>\n",
       "      <td>-0.572302</td>\n",
       "      <td>1.105587</td>\n",
       "      <td>-1.208016</td>\n",
       "      <td>-1.339701</td>\n",
       "      <td>2.075185</td>\n",
       "      <td>-1.489410</td>\n",
       "      <td>-1.150953</td>\n",
       "      <td>0.419060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weights btw layer0 to layer1</td>\n",
       "      <td>0.523546</td>\n",
       "      <td>0.821517</td>\n",
       "      <td>-0.148742</td>\n",
       "      <td>-0.045370</td>\n",
       "      <td>-0.704493</td>\n",
       "      <td>1.730316</td>\n",
       "      <td>0.228927</td>\n",
       "      <td>1.092741</td>\n",
       "      <td>-0.353572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050050</td>\n",
       "      <td>0.743953</td>\n",
       "      <td>-1.724050</td>\n",
       "      <td>0.089902</td>\n",
       "      <td>0.322740</td>\n",
       "      <td>-0.377149</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>1.050114</td>\n",
       "      <td>-0.168699</td>\n",
       "      <td>0.797876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   weights btw layer0 to layer1  0.471435159  -1.190975666  1.432706952  \\\n",
       "0  weights btw layer0 to layer1     0.291205      0.566534     0.503592   \n",
       "1  weights btw layer0 to layer1    -0.319561     -0.619993     0.156998   \n",
       "2  weights btw layer0 to layer1     0.527046      0.711112    -0.217545   \n",
       "3  weights btw layer0 to layer1    -0.226632     -0.923831     0.355839   \n",
       "4  weights btw layer0 to layer1     0.523546      0.821517    -0.148742   \n",
       "\n",
       "   -0.312651902  -0.720588744  0.887162924  0.859588385  -0.636523485  \\\n",
       "0      0.285296      0.484288     1.363482    -0.781105     -0.468018   \n",
       "1     -0.571455      1.057633    -0.791489    -0.524627      0.071878   \n",
       "2      2.637791     -1.742138    -0.094435     1.431184      0.592758   \n",
       "3     -1.270064     -0.195472    -0.463419     0.989415      1.388647   \n",
       "4     -0.045370     -0.704493     1.730316     0.228927      1.092741   \n",
       "\n",
       "   0.015696373  ...  -0.54824245  -0.14461951  0.354020327  -0.035513025  \\\n",
       "0     1.224574  ...     1.357797    -0.804834    -2.123620     -0.333502   \n",
       "1     1.910759  ...     0.003760    -1.268994    -0.838843      0.553921   \n",
       "2     0.170297  ...    -1.337968    -0.041387     0.821048      2.097801   \n",
       "3     1.087714  ...    -0.588227     0.025942    -0.572302      1.105587   \n",
       "4    -0.353572  ...    -0.050050     0.743953    -1.724050      0.089902   \n",
       "\n",
       "   0.56573832  1.545658827  -0.97423631  -0.07034488  0.307968855  \\\n",
       "0   -0.886719     0.334198     0.536784    -0.743830    -0.320204   \n",
       "1   -0.504043    -0.788440     1.529401     0.205455     0.313013   \n",
       "2    1.282933     0.270338     1.003140     1.078674     0.340753   \n",
       "3   -1.208016    -1.339701     2.075185    -1.489410    -1.150953   \n",
       "4    0.322740    -0.377149    -0.000221     1.050114    -0.168699   \n",
       "\n",
       "   -0.208498761  \n",
       "0     -0.916199  \n",
       "1      0.866521  \n",
       "2     -0.198075  \n",
       "3      0.419060  \n",
       "4      0.797876  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('W.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16261350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias for layer1</th>\n",
       "      <th>-0.635154963</th>\n",
       "      <th>-0.681020141</th>\n",
       "      <th>-1.501585722</th>\n",
       "      <th>-0.368925124</th>\n",
       "      <th>-0.352999359</th>\n",
       "      <th>0.127384394</th>\n",
       "      <th>0.517531335</th>\n",
       "      <th>0.747836828</th>\n",
       "      <th>-0.809377551</th>\n",
       "      <th>...</th>\n",
       "      <th>-0.749805033</th>\n",
       "      <th>-0.267733008</th>\n",
       "      <th>0.631269991</th>\n",
       "      <th>-0.087142929</th>\n",
       "      <th>-0.069249019</th>\n",
       "      <th>-0.167822808</th>\n",
       "      <th>0.649498701</th>\n",
       "      <th>0.620435476</th>\n",
       "      <th>0.144408464</th>\n",
       "      <th>1.160045505</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bias for layer2</td>\n",
       "      <td>0.665451</td>\n",
       "      <td>1.426556</td>\n",
       "      <td>1.158077</td>\n",
       "      <td>-0.496191</td>\n",
       "      <td>-0.010350</td>\n",
       "      <td>0.617206</td>\n",
       "      <td>0.336297</td>\n",
       "      <td>-0.358238</td>\n",
       "      <td>-0.995016</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bias for layer3</td>\n",
       "      <td>-1.027926</td>\n",
       "      <td>-1.870784</td>\n",
       "      <td>0.661100</td>\n",
       "      <td>-1.804633</td>\n",
       "      <td>1.165536</td>\n",
       "      <td>0.663858</td>\n",
       "      <td>0.156078</td>\n",
       "      <td>0.413614</td>\n",
       "      <td>1.211116</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bias for layer4</td>\n",
       "      <td>1.508889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias for layer1  -0.635154963  -0.681020141  -1.501585722  -0.368925124  \\\n",
       "0  bias for layer2      0.665451      1.426556      1.158077     -0.496191   \n",
       "1  bias for layer3     -1.027926     -1.870784      0.661100     -1.804633   \n",
       "2  bias for layer4      1.508889           NaN           NaN           NaN   \n",
       "\n",
       "   -0.352999359  0.127384394  0.517531335  0.747836828  -0.809377551  ...  \\\n",
       "0     -0.010350     0.617206     0.336297    -0.358238     -0.995016  ...   \n",
       "1      1.165536     0.663858     0.156078     0.413614      1.211116  ...   \n",
       "2           NaN          NaN          NaN          NaN           NaN  ...   \n",
       "\n",
       "   -0.749805033  -0.267733008  0.631269991  -0.087142929  -0.069249019  \\\n",
       "0           NaN           NaN          NaN           NaN           NaN   \n",
       "1           NaN           NaN          NaN           NaN           NaN   \n",
       "2           NaN           NaN          NaN           NaN           NaN   \n",
       "\n",
       "   -0.167822808  0.649498701  0.620435476  0.144408464  1.160045505  \n",
       "0           NaN          NaN          NaN          NaN          NaN  \n",
       "1           NaN          NaN          NaN          NaN          NaN  \n",
       "2           NaN          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[3 rows x 65 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('b.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881e75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a1f676",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 165\u001b[0m\n\u001b[0;32m    162\u001b[0m index_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m123456\u001b[39m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Initialize neural network\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m nn \u001b[38;5;241m=\u001b[39m \u001b[43mNeuralNetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mW.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n\u001b[0;32m    168\u001b[0m dw, db \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mcompute_gradients(index_number)\n",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m, in \u001b[0;36mNeuralNetwork.__init__\u001b[1;34m(self, weights_file, biases_file)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights_file, biases_file):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Load weights and biases from CSV files\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbiases \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_biases(biases_file)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Define activation functions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m, in \u001b[0;36mNeuralNetwork.load_weights\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;66;03m# Skip the first column (index column)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m row:  \u001b[38;5;66;03m# Check if row is not empty\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m             data\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Reshape weights according to network architecture\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Input to Hidden1: 6x64\u001b[39;00m\n\u001b[0;32m     30\u001b[0m w1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m6\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, weights_file, biases_file):\n",
    "        # Load weights and biases from CSV files\n",
    "        self.weights = self.load_weights(weights_file)\n",
    "        self.biases = self.load_biases(biases_file)\n",
    "        \n",
    "        # Define activation functions\n",
    "        self.relu = lambda x: np.maximum(0, x)\n",
    "        self.sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        # Define derivatives of activation functions\n",
    "        self.relu_derivative = lambda x: (x > 0).astype(np.float32)\n",
    "        self.sigmoid_derivative = lambda x: x * (1 - x)\n",
    "    \n",
    "    def load_weights(self, filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)  # Skip header\n",
    "            data = []\n",
    "            for row in reader:\n",
    "                # Skip the first column (index column)\n",
    "                if row:  # Check if row is not empty\n",
    "                    data.append(list(map(np.float32, row[1:])))\n",
    "        \n",
    "        # Reshape weights according to network architecture\n",
    "        # Input to Hidden1: 6x64\n",
    "        w1 = np.array(data[0:6])\n",
    "        # Hidden1 to Hidden2: 64x32\n",
    "        w2 = np.array(data[6:6+64])\n",
    "        # Hidden2 to Hidden3: 32x16\n",
    "        w3 = np.array(data[6+64:6+64+32])\n",
    "        # Hidden3 to Output: 16x1\n",
    "        w4 = np.array(data[6+64+32:6+64+32+16])\n",
    "        \n",
    "        return [w1, w2, w3, w4]\n",
    "    \n",
    "    def load_biases(self, filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader)  # Skip header\n",
    "            data = []\n",
    "            for row in reader:\n",
    "                # Skip the first column (index column)\n",
    "                if row:  # Check if row is not empty\n",
    "                    data.append(list(map(np.float32, row[1:])))\n",
    "        \n",
    "        # Reshape biases according to network architecture\n",
    "        # Hidden1: 64\n",
    "        b1 = np.array(data[0]).reshape(-1, 1)\n",
    "        # Hidden2: 32\n",
    "        b2 = np.array(data[1]).reshape(-1, 1)\n",
    "        # Hidden3: 16\n",
    "        b3 = np.array(data[2]).reshape(-1, 1)\n",
    "        # Output: 1\n",
    "        b4 = np.array(data[3]).reshape(-1, 1)\n",
    "        \n",
    "        return [b1, b2, b3, b4]\n",
    "    \n",
    "    def forward_pass(self, x):\n",
    "        # Store intermediate values for backpropagation\n",
    "        self.activations = [x.reshape(-1, 1)]\n",
    "        self.z_values = []\n",
    "        \n",
    "        # Hidden Layer 1\n",
    "        z1 = self.weights[0].T @ self.activations[0] + self.biases[0]\n",
    "        a1 = self.relu(z1)\n",
    "        self.z_values.append(z1)\n",
    "        self.activations.append(a1)\n",
    "        \n",
    "        # Hidden Layer 2\n",
    "        z2 = self.weights[1].T @ a1 + self.biases[1]\n",
    "        a2 = self.relu(z2)\n",
    "        self.z_values.append(z2)\n",
    "        self.activations.append(a2)\n",
    "        \n",
    "        # Hidden Layer 3\n",
    "        z3 = self.weights[2].T @ a2 + self.biases[2]\n",
    "        a3 = self.relu(z3)\n",
    "        self.z_values.append(z3)\n",
    "        self.activations.append(a3)\n",
    "        \n",
    "        # Output Layer\n",
    "        z4 = self.weights[3].T @ a3 + self.biases[3]\n",
    "        a4 = self.sigmoid(z4)\n",
    "        self.z_values.append(z4)\n",
    "        self.activations.append(a4)\n",
    "        \n",
    "        return a4\n",
    "    \n",
    "    def backpropagation(self):\n",
    "        # Initialize gradients\n",
    "        dw = [np.zeros_like(w) for w in self.weights]\n",
    "        db = [np.zeros_like(b) for b in self.biases]\n",
    "        \n",
    "        # Output layer gradient\n",
    "        delta = 1  # output/output = 1\n",
    "        delta *= self.sigmoid_derivative(self.activations[4])  # output/z4\n",
    "        \n",
    "        db[3] = delta\n",
    "        dw[3] = self.activations[3] @ delta.T\n",
    "        \n",
    "        # Hidden Layer 3\n",
    "        delta = self.weights[3] @ delta  # output/a3\n",
    "        delta *= self.relu_derivative(self.z_values[2])  # output/z3\n",
    "        \n",
    "        db[2] = delta\n",
    "        dw[2] = self.activations[2] @ delta.T\n",
    "        \n",
    "        # Hidden Layer 2\n",
    "        delta = self.weights[2] @ delta  # output/a2\n",
    "        delta *= self.relu_derivative(self.z_values[1])  # output/z2\n",
    "        \n",
    "        db[1] = delta\n",
    "        dw[1] = self.activations[1] @ delta.T\n",
    "        \n",
    "        # Hidden Layer 1\n",
    "        delta = self.weights[1] @ delta  # output/a1\n",
    "        delta *= self.relu_derivative(self.z_values[0])  # output/z1\n",
    "        \n",
    "        db[0] = delta\n",
    "        dw[0] = self.activations[0] @ delta.T\n",
    "        \n",
    "        return dw, db\n",
    "    \n",
    "    def preprocess_input(self, index_number):\n",
    "        # Split into digits and normalize\n",
    "        digits = [int(d) for d in str(index_number)]\n",
    "        return np.array(digits, dtype=np.float32) / 9.0\n",
    "    \n",
    "    def compute_gradients(self, index_number):\n",
    "        # Preprocess input\n",
    "        x = self.preprocess_input(index_number)\n",
    "        \n",
    "        # Forward pass\n",
    "        self.forward_pass(x)\n",
    "        \n",
    "        # Backpropagation\n",
    "        dw, db = self.backpropagation()\n",
    "        \n",
    "        return dw, db\n",
    "\n",
    "def save_gradients(dw, db, dw_filename, db_filename):\n",
    "    # Save weight gradients\n",
    "    with open(dw_filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for layer in dw:\n",
    "            for row in layer:\n",
    "                writer.writerow([f\"{x:.16f}\" for x in row])\n",
    "    \n",
    "    # Save bias gradients\n",
    "    with open(db_filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for layer in db:\n",
    "            writer.writerow([f\"{x:.16f}\" for x in layer.flatten()])\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your index number\n",
    "    index_number = 123456\n",
    "    \n",
    "    # Initialize neural network\n",
    "    nn = NeuralNetwork('W.csv', 'b.csv')\n",
    "    \n",
    "    # Compute gradients\n",
    "    dw, db = nn.compute_gradients(index_number)\n",
    "    \n",
    "    # Save gradients to CSV files\n",
    "    save_gradients(dw, db, 'dw.csv', 'db.csv')\n",
    "    \n",
    "    print(\"Gradients computed and saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
