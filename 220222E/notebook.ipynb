{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c1a8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight matrix shape: (118, 64)\n",
      "Bias matrix shape: (4, 64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load a CSV matrix (ignore first column)\n",
    "def import_matrix(file_path: str) -> np.ndarray:\n",
    "    try:\n",
    "        data = pd.read_csv(file_path, header=None)\n",
    "        return np.nan_to_num(data.iloc[:, 1:].to_numpy(), nan=0.0)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File {file_path} not found\")\n",
    "\n",
    "# Load parameter placeholders\n",
    "try:\n",
    "    weight_raw = import_matrix(\"W.csv\")\n",
    "    bias_raw = import_matrix(\"b.csv\")\n",
    "    print(\"Weight matrix shape:\", weight_raw.shape)\n",
    "    print(\"Bias matrix shape:\", bias_raw.shape)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading matrices: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "# Partition weights and biases per layer\n",
    "\n",
    "def slice_weights(full_w, arch):\n",
    "    mats = []\n",
    "    start = 0\n",
    "    for in_size, out_size in arch:\n",
    "        mats.append(full_w[start:start + in_size, :out_size])\n",
    "        start += in_size\n",
    "    return mats\n",
    "\n",
    "def slice_biases(full_b, outs):\n",
    "    return [full_b[i, :dim] for i, dim in enumerate(outs)]\n",
    "\n",
    "# Model architecture\n",
    "net_arch = [(6, 64), (64, 32), (32, 16), (16, 1)]\n",
    "out_shapes = [64, 32, 16, 1]\n",
    "\n",
    "# Validate shapes\n",
    "expected_w_rows = sum(in_size for in_size, _ in net_arch)\n",
    "if weight_raw.shape[0] != expected_w_rows or weight_raw.shape[1] != max(out_shapes):\n",
    "    raise ValueError(\"Weight matrix shape mismatch\")\n",
    "if bias_raw.shape[0] != len(out_shapes) or bias_raw.shape[1] != max(out_shapes):\n",
    "    raise ValueError(\"Bias matrix shape mismatch\")\n",
    "\n",
    "weight_layers = slice_weights(weight_raw, net_arch)\n",
    "bias_layers = slice_biases(bias_raw, out_shapes)\n",
    "W1, W2, W3, W4 = weight_layers\n",
    "b1, b2, b3, b4 = bias_layers\n",
    "\n",
    "# Activation functions\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def sigmoid(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "def Gradient_ReLU(Z):\n",
    "    return (Z > 0).astype(float)\n",
    "\n",
    "# Forward propagation\n",
    "def forward_propagation(X, W1, b1, W2, b2, W3, b3, W4, b4):\n",
    "    Z1 = X @ W1 + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    \n",
    "    Z2 = A1 @ W2 + b2\n",
    "    A2 = ReLU(Z2)\n",
    "    \n",
    "    Z3 = A2 @ W3 + b3\n",
    "    A3 = ReLU(Z3)\n",
    "    \n",
    "    Z4 = A3 @ W4 + b4\n",
    "    A4 = sigmoid(Z4)\n",
    "    \n",
    "    return Z1, A1, Z2, A2, Z3, A3, Z4, A4\n",
    "\n",
    "# Backward propagation\n",
    "def backward_propagation(W1, b1, W2, b2, W3, b3, W4, b4, Z1, A1, Z2, A2, Z3, A3, Z4, A4, X, Y):\n",
    "    m = X.shape[0]\n",
    "    dZ4 = A4 - Y\n",
    "    dW4 = (A3.T @ dZ4) / m\n",
    "    db4 = np.sum(dZ4, axis=0, keepdims=True) / m\n",
    "    \n",
    "    dZ3 = (dZ4 @ W4.T) * Gradient_ReLU(Z3)\n",
    "    dW3 = (A2.T @ dZ3) / m\n",
    "    db3 = np.sum(dZ3, axis=0, keepdims=True) / m\n",
    "    \n",
    "    dZ2 = (dZ3 @ W3.T) * Gradient_ReLU(Z2)\n",
    "    dW2 = (A1.T @ dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "    \n",
    "    dZ1 = (dZ2 @ W2.T) * Gradient_ReLU(Z1)\n",
    "    dW1 = (X.T @ dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "    \n",
    "    return dW1, db1, dW2, db2, dW3, db3, dW4, db4\n",
    "\n",
    "# Update parameters\n",
    "def update_parameters(W1, b1, W2, b2, W3, b3, W4, b4, dW1, db1, dW2, db2, dW3, db3, dW4, db4, learning_rate):\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    W3 -= learning_rate * dW3\n",
    "    b3 -= learning_rate * db3\n",
    "    W4 -= learning_rate * dW4\n",
    "    b4 -= learning_rate * db4\n",
    "    \n",
    "    return W1, b1, W2, b2, W3, b3, W4, b4\n",
    "\n",
    "# Get predictions\n",
    "def get_predictions(A4):\n",
    "    return (A4 > 0.5).astype(int)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.mean(predictions == Y)\n",
    "\n",
    "# Gradient descent\n",
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2, Z3, A3, Z4, A4 = forward_propagation(X, W1, b1, W2, b2, W3, b3, W4, b4)\n",
    "        dW1, db1, dW2, db2, dW3, db3, dW4, db4 = backward_propagation(W1, b1, W2, b2, W3, b3, W4, b4, \n",
    "                                                                     Z1, A1, Z2, A2, Z3, A3, Z4, A4, X, Y)\n",
    "        W1, b1, W2, b2, W3, b3, W4, b4 = update_parameters(W1, b1, W2, b2, W3, b3, W4, b4, \n",
    "                                                          dW1, db1, dW2, db2, dW3, db3, dW4, db4, alpha)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            predictions = get_predictions(A4)\n",
    "            accuracy = get_accuracy(predictions, Y)\n",
    "            print(f\"Iteration {i}, Accuracy: {accuracy}\")\n",
    "    \n",
    "    return W1, b1, W2, b2, W3, b3, W4, b4\n",
    "\n",
    "# Export gradients function\n",
    "def export_grads(grad_dict, arch, out_shapes, W_template, B_template):\n",
    "    dW_full = np.full_like(W_template, np.nan, dtype=np.float32)\n",
    "    dB_full = np.full_like(B_template, np.nan, dtype=np.float32)\n",
    "\n",
    "    # Reuse slicing logic for weights\n",
    "    start = 0\n",
    "    for i, (in_size, out_size) in enumerate(arch):\n",
    "        dW_full[start:start + in_size, :out_size] = grad_dict[f\"dW{i+1}\"]\n",
    "        start += in_size\n",
    "\n",
    "    # Reuse slicing logic for biases\n",
    "    for i, dim in enumerate(out_shapes):\n",
    "        dB_full[i, :dim] = grad_dict[f\"db{i+1}\"]\n",
    "\n",
    "    try:\n",
    "        pd.DataFrame(dW_full).to_csv(\"dw_123456.csv\", index=False, header=False, float_format=\"%.16f\")\n",
    "        pd.DataFrame(dB_full).to_csv(\"db_123456.csv\", index=False, header=False, float_format=\"%.16f\")\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Error saving gradients: {e}\")\n",
    "\n",
    "# Example execution\n",
    "student_code = \"123456\"\n",
    "try:\n",
    "    x_in = np.array([int(ch) for ch in student_code], dtype=float).reshape(1, -1) / 9.0\n",
    "    if x_in.shape[1] != net_arch[0][0]:\n",
    "        raise ValueError(f\"Input size {x_in.shape[1]} does not match expected {net_arch[0][0]}\")\n",
    "    y_target = np.array([[0]])\n",
    "\n",
    "    # Forward pass\n",
    "    Z1, A1, Z2, A2, Z3, A3, Z4, A4 = forward_propagation(x_in, W1, b1, W2, b2, W3, b3, W4, b4)\n",
    "    \n",
    "    # Backward pass\n",
    "    dW1, db1, dW2, db2, dW3, db3, dW4, db4 = backward_propagation(W1, b1, W2, b2, W3, b3, W4, b4, \n",
    "                                                                 Z1, A1, Z2, A2, Z3, A3, Z4, A4, x_in, y_target)\n",
    "\n",
    "    # Bundle gradients for export\n",
    "    grad_bundle = {\n",
    "        \"dW1\": dW1, \"db1\": db1,\n",
    "        \"dW2\": dW2, \"db2\": db2,\n",
    "        \"dW3\": dW3, \"db3\": db3,\n",
    "        \"dW4\": dW4, \"db4\": db4,\n",
    "    }\n",
    "\n",
    "    export_grads(grad_bundle, net_arch, out_shapes, weight_raw, bias_raw)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during execution: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884cb3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score: 122\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Script for student\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "ID = '123456'  # Index number\n",
    "\n",
    "file_name = ['dw_123456.csv', 'db_123456.csv']  # generated files\n",
    "truth_path = ['true_dw_123456.csv', 'true_db_123456.csv']  # true files\n",
    "threshold = 0.05\n",
    "\n",
    "\n",
    "def read_file(name):\n",
    "    data = []\n",
    "    with open(name) as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            cleaned_row = [np.float32(x) if x != '' else np.float32(0) for x in row]\n",
    "            data.append(cleaned_row)\n",
    "    return data\n",
    "\n",
    "\n",
    "def grade(l0, l1, th):\n",
    "    dif = np.mean(np.abs(l0 - l1).astype(float) / (0.1 + l1))\n",
    "    return 1 if dif <= th else 0\n",
    "\n",
    "\n",
    "def compare(sub, true, threshold=0):\n",
    "    if len(sub) != len(true):\n",
    "        return 0\n",
    "    scores = []\n",
    "    for row_sub, row_true in zip(sub, true):\n",
    "        l0 = np.array(row_sub).astype(float)\n",
    "        l1 = np.array(row_true).astype(float)\n",
    "        if len(l0) != len(l1):\n",
    "            return 0\n",
    "        scores.append(grade(l0, l1, threshold))\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Read all files\n",
    "student_grads = [read_file(f) for f in file_name]\n",
    "true_grads = [read_file(f) for f in truth_path]\n",
    "\n",
    "# Compare and score\n",
    "score = []\n",
    "for sub, true in zip(student_grads, true_grads):\n",
    "    s = compare(sub, true, threshold)\n",
    "    if isinstance(s, list):\n",
    "        score += s\n",
    "    else:\n",
    "        score.append(s)\n",
    "\n",
    "print(\"Total score:\",np.sum(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
